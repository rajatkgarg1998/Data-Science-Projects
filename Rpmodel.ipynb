{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ9e3IU1E1nj"
      },
      "outputs": [],
      "source": [
        "pip install pyunicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x_dLMQWEzbY"
      },
      "outputs": [],
      "source": [
        "pip install netCDF4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install audiomentations"
      ],
      "metadata": {
        "id": "RRy1XxvCZcuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrence Plot**"
      ],
      "metadata": {
        "id": "hK1t0kg_bkeU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VHxHQdPYINo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pyunicorn.timeseries.recurrence_plot import RecurrencePlot\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Read the wav file\n",
        "sample_rate, audio_data = wavfile.read('03.wav')\n",
        "\n",
        "# Convert to mono if necessary\n",
        "if audio_data.ndim > 1:\n",
        "    audio_data = np.mean(audio_data, axis=1)\n",
        "\n",
        "# Define the segment size\n",
        "segment_size = 600\n",
        "\n",
        "# Loop over the audio data in segment_size increments\n",
        "for i in range(0, len(audio_data), segment_size):\n",
        "    # Extract the current segment\n",
        "    audio_data_segment = audio_data[i:i+segment_size]\n",
        "\n",
        "    # Create a recurrence plot with a distance threshold of 0.1\n",
        "    rp = RecurrencePlot(audio_data_segment, dim=1, tau=10, threshold=0.1, normalize=True)\n",
        "\n",
        "    # Plot the recurrence plot using imshow\n",
        "    plt.imshow(rp.recurrence_matrix(), cmap='binary', origin='lower')\n",
        "    plt.title(f'Recurrence plot for segment {i+1}')\n",
        "    plt.xlabel('Time (samples)')\n",
        "    plt.ylabel('Time (samples)')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2cyiXy_d0Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fo0wH4bSd0Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convo 2D MODEL**"
      ],
      "metadata": {
        "id": "_K_AeYEgkwoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "5ThzfLm_rMBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from pyunicorn.timeseries.recurrence_plot import RecurrencePlot\n",
        "from scipy.io import wavfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def extract_recurrence_plot_features(audio_data, segment_size):\n",
        "    features = []\n",
        "    num_segments = len(audio_data) // segment_size\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_size\n",
        "        end = start + segment_size\n",
        "        audio_data_segment = audio_data[start:end]\n",
        "\n",
        "        # Perform recurrence plot feature extraction\n",
        "        # Example using pyunicorn recurrence plot\n",
        "        rp = RecurrencePlot(audio_data_segment, dim=1, tau=10, threshold=0.1, normalize=True)\n",
        "        recurrence_matrix = rp.recurrence_matrix()\n",
        "\n",
        "        features.append(recurrence_matrix)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Function to load audio data and extract recurrence plot features\n",
        "def load_data_and_extract_features(data_dir, segment_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    speakers = os.listdir(data_dir)\n",
        "    for speaker in speakers:\n",
        "        speaker_dir = os.path.join(data_dir, speaker)\n",
        "        if os.path.isdir(speaker_dir):\n",
        "            words = os.listdir(speaker_dir)\n",
        "            for word in words:\n",
        "                word_dir = os.path.join(speaker_dir, word)\n",
        "                if os.path.isdir(word_dir):\n",
        "                    audio_files = os.listdir(word_dir)\n",
        "                    for audio_file in audio_files:\n",
        "                        if audio_file.endswith('.wav'):\n",
        "                            audio_path = os.path.join(word_dir, audio_file)\n",
        "                            sample_rate, audio_data = wavfile.read(audio_path)\n",
        "                            if audio_data.ndim > 1:\n",
        "                                audio_data = np.mean(audio_data, axis=1)\n",
        "                            extracted_features = extract_recurrence_plot_features(audio_data, segment_size)\n",
        "                            features.extend(extracted_features)\n",
        "                            labels.extend([speaker] * len(extracted_features))\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Set the directory containing the audio data\n",
        "data_dir = '/content/dataset'\n",
        "\n",
        "# Set the segment size\n",
        "segment_size = 600\n",
        "\n",
        "# Load the audio data and extract recurrence plot features\n",
        "features, labels = load_data_and_extract_features(data_dir, segment_size)\n",
        "\n",
        "# Check if features are extracted\n",
        "if len(features) > 0:\n",
        "    # Get the size of the first feature\n",
        "    feature_shape = features[0].shape\n",
        "\n",
        "    # Check if all features have the same shape\n",
        "    if all(feature.shape == feature_shape for feature in features):\n",
        "        # Convert features to numpy array\n",
        "        features = np.array(features)\n",
        "\n",
        "        # Preprocess the features (e.g., normalization)\n",
        "        # ...\n",
        "\n",
        "        # Encode labels as categorical\n",
        "        label_names = np.unique(labels)\n",
        "        num_classes = len(label_names)\n",
        "        label_mapping = {label: i for i, label in enumerate(label_names)}\n",
        "        labels = np.array([label_mapping[label] for label in labels])\n",
        "        labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Reshape the features for 2D convolution\n",
        "        input_shape = (feature_shape[0], feature_shape[1], 1)\n",
        "        X_train = X_train.reshape((*X_train.shape, 1))\n",
        "        X_test = X_test.reshape((*X_test.shape, 1))\n",
        "\n",
        "        # Define the convolutional neural network model\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "        # Evaluate the model\n",
        "        loss, accuracy = model.evaluate(X_test, y_test)\n",
        "        print(f'Test Loss: {loss:.4f}')\n",
        "        print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "        # Save the model\n",
        "        model.save('speaker_recognition_model.h5')\n",
        "    else:\n",
        "        print(\"Features have different shapes. Please ensure all features have the same shape.\")\n",
        "else:\n",
        "    print(\"No features extracted from the audio data.\")\n"
      ],
      "metadata": {
        "id": "H9GQnjFjqlbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "233ROHB_qlfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fA3fOY62-OFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iUGM4Be-OHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gz2wuCpE-OLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delete Folder**"
      ],
      "metadata": {
        "id": "MyiRYm_l-Oql"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kd8Q56cjCJt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the path of the folder to be deleted\n",
        "folder_path = '/content/dataset'\n",
        "\n",
        "# Use shutil.rmtree() to delete the folder and its contents\n",
        "shutil.rmtree(folder_path)"
      ],
      "metadata": {
        "id": "avwcjP8wfi25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZbdbzL3fi7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmkSwfFF8CRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-u8T81vB8CTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GempnGrx8CWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j4ckD7IbfjBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ALEX NET**"
      ],
      "metadata": {
        "id": "os3d3CK7Dp01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from pyunicorn.timeseries.recurrence_plot import RecurrencePlot\n",
        "from scipy.io import wavfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def extract_recurrence_plot_features(audio_data, segment_size):\n",
        "    features = []\n",
        "    num_segments = len(audio_data) // segment_size\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_size\n",
        "        end = start + segment_size\n",
        "        audio_data_segment = audio_data[start:end]\n",
        "\n",
        "        # Perform recurrence plot feature extraction\n",
        "        # Example using pyunicorn recurrence plot\n",
        "        rp = RecurrencePlot(audio_data_segment, dim=1, tau=10, threshold=0.1, normalize=True)\n",
        "        recurrence_matrix = rp.recurrence_matrix()\n",
        "\n",
        "        features.append(recurrence_matrix)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Function to load audio data and extract recurrence plot features\n",
        "def load_data_and_extract_features(data_dir, segment_size):\n",
        "    features = []\n",
        "    labels = []\n",
        "    speakers = os.listdir(data_dir)\n",
        "    for speaker in speakers:\n",
        "        speaker_dir = os.path.join(data_dir, speaker)\n",
        "        if os.path.isdir(speaker_dir):\n",
        "            words = os.listdir(speaker_dir)\n",
        "            for word in words:\n",
        "                word_dir = os.path.join(speaker_dir, word)\n",
        "                if os.path.isdir(word_dir):\n",
        "                    audio_files = os.listdir(word_dir)\n",
        "                    for audio_file in audio_files:\n",
        "                        if audio_file.endswith('.wav'):\n",
        "                            audio_path = os.path.join(word_dir, audio_file)\n",
        "                            sample_rate, audio_data = wavfile.read(audio_path)\n",
        "                            if audio_data.ndim > 1:\n",
        "                                audio_data = np.mean(audio_data, axis=1)\n",
        "                            extracted_features = extract_recurrence_plot_features(audio_data, segment_size)\n",
        "                            features.extend(extracted_features)\n",
        "                            labels.extend([speaker] * len(extracted_features))\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Set the directory containing the audio data\n",
        "data_dir = '/content/dataset'\n",
        "\n",
        "# Set the segment size\n",
        "segment_size = 600\n",
        "\n",
        "# Load the audio data and extract recurrence plot features\n",
        "features, labels = load_data_and_extract_features(data_dir, segment_size)\n",
        "\n",
        "# Check if features are extracted\n",
        "if len(features) > 0:\n",
        "    # Get the shape of the first feature\n",
        "    feature_shape = features[0].shape\n",
        "\n",
        "    # Check if all features have the same shape\n",
        "    if all(feature.shape == feature_shape for feature in features):\n",
        "        # Convert features to numpy array\n",
        "        features = np.array(features)\n",
        "\n",
        "        # Preprocess the features (e.g., normalization)\n",
        "        # ...\n",
        "\n",
        "        # Encode labels as categorical\n",
        "        label_names = np.unique(labels)\n",
        "        num_classes = len(label_names)\n",
        "        label_mapping = {label: i for i, label in enumerate(label_names)}\n",
        "        labels = np.array([label_mapping[label] for label in labels])\n",
        "        labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Reshape the features for 2D convolution\n",
        "        input_shape = (feature_shape[0], feature_shape[1], 1)\n",
        "        X_train = X_train.reshape((*X_train.shape, 1))\n",
        "        X_test = X_test.reshape((*X_test.shape, 1))\n",
        "\n",
        "        # Define the AlexNet architecture\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "        model.add(Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "        model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "        # Evaluate the model\n",
        "        loss, accuracy = model.evaluate(X_test, y_test)\n",
        "        print(f'Test Loss: {loss:.4f}')\n",
        "        print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "        # Save the model\n",
        "        model.save('speaker_recognition_model.h5')\n",
        "    else:\n",
        "        print(\"Features have different shapes. Please ensure all features have the same shape.\")\n",
        "else:\n",
        "    print(\"No features extracted from the audio data.\")\n"
      ],
      "metadata": {
        "id": "dFhY_HDRd0Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ATLSy6_2RPXK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQji8b_Ed0a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MGGw7NCEqw9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yxjx05-dqw_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_twFHpk5qxBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k2esnSGaCj6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rcio-IzKMZat"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}